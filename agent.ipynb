{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, window_size, trend, skip, batch_size, volume, day_of_week,dayofyear,EMA_20,MACD,Signal_Line):\n",
    "        self.volume = volume\n",
    "        self.day_of_week = day_of_week\n",
    "        \n",
    "        self.dayofyear = dayofyear\n",
    "        self.EMA_20 = EMA_20\n",
    "        self.MACD = MACD\n",
    "        self.Signal_Line = Signal_Line\n",
    "        \n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.action_size = 3\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=batch_size)\n",
    "        self.inventory = []\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 0.5\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.999\n",
    "\n",
    "        # self.model = self.build_model()\n",
    "\n",
    "    def build_model(self,PARAMS ):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(PARAMS['unit1'], activation='relu', input_shape=(self.state_size,)),\n",
    "            tf.keras.layers.Dense(PARAMS['unit2'], activation='relu'),\n",
    "            tf.keras.layers.Dense(PARAMS['unit3'], activation='relu'),\n",
    "            tf.keras.layers.Dense(self.action_size)\n",
    "        ])\n",
    "        optimizer_model = tf.keras.optimizers.get(PARAMS['optimizer'])\n",
    "        if PARAMS['learning_rate'] != 0:\n",
    "            optimizer_model.learning_rate = PARAMS['learning_rate']\n",
    "        model.compile(optimizer_model, loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        return np.argmax(self.model.predict(state.reshape(1, self.state_size),verbose = 0)[0])\n",
    "    def get_state(self, t):\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
    "        block_volume = self.volume[d : t] if d >= 0 else -d * [self.volume[0]] + self.volume[0 : t]  # adjusted slicing\n",
    "        block_day_of_week = self.day_of_week[d : t] if d >= 0 else -d * [self.day_of_week[0]] + self.day_of_week[0 : t]  # adjusted slicing\n",
    "        \n",
    "        block_dayofyear = self.dayofyear[d : t] if d >= 0 else -d * [self.dayofyear[0]] + self.dayofyear[0 : t]  # adjusted slicing\n",
    "        block_EMA_20 = self.EMA_20[d : t] if d >= 0 else -d * [self.EMA_20[0]] + self.EMA_20[0 : t]  # adjusted slicing\n",
    "        block_MACD = self.MACD[d : t] if d >= 0 else -d * [self.MACD[0]] + self.MACD[0 : t]  # adjusted slicing\n",
    "        block_Signal_Line= self.Signal_Line[d : t] if d >= 0 else -d * [self.Signal_Line[0]] + self.Signal_Line[0 : t]  # adjusted slicing\n",
    "        \n",
    "        res = np.concatenate((np.diff(block), block_volume, block_day_of_week,block_dayofyear,block_EMA_20,block_MACD,block_Signal_Line), axis=None)\n",
    "        return np.array([res])\n",
    "    def replay(self, batch_size):\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([state for state, _, _, _, _ in mini_batch])\n",
    "        actions = np.array([action for _, action, _, _, _ in mini_batch])\n",
    "        rewards = np.array([reward for _, _, reward, _, _ in mini_batch])\n",
    "        next_states = np.array([next_state for _, _, _, next_state, _ in mini_batch])\n",
    "        dones = np.array([done for _, _, _, _, done in mini_batch])\n",
    "\n",
    "        targets = self.model.predict(states)\n",
    "        next_state_targets = self.model.predict(next_states)\n",
    "        max_next_state_targets = np.max(next_state_targets, axis=1)\n",
    "\n",
    "        targets[np.arange(batch_size), actions] = rewards + self.gamma * max_next_state_targets * (1 - dones)\n",
    "\n",
    "        self.model.fit(states, targets, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def buy(self, initial_money):\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        state = self.get_state(0)\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "\n",
    "            if action == 1 and initial_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                inventory.append(self.trend[t])\n",
    "                initial_money -= self.trend[t]\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy 1 unit at price %f, total balance %f' % (t, self.trend[t], initial_money))\n",
    "\n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                initial_money += self.trend[t]\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((close[t] - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print('day %d, sell 1 unit at price %f, investment %f %%, total balance %f,' %\n",
    "                      (t, close[t], invest, initial_money))\n",
    "\n",
    "            state = next_state\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        total_gains = initial_money - starting_money\n",
    "        return states_buy, states_sell, total_gains, invest\n",
    "\n",
    "    def train(self, iterations, checkpoint, initial_money):\n",
    "        for i in range(iterations):\n",
    "            total_profit = 0\n",
    "            inventory = []\n",
    "            state = self.get_state(0)\n",
    "            starting_money = initial_money\n",
    "            for t in range(0, len(self.trend) - 1, self.skip):\n",
    "                action = self.act(state)\n",
    "                next_state = self.get_state(t + 1)\n",
    "\n",
    "                if action == 1 and starting_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                    inventory.append(self.trend[t])\n",
    "                    starting_money -= self.trend[t]\n",
    "\n",
    "                elif action == 2 and len(inventory) > 0:\n",
    "                    bought_price = inventory.pop(0)\n",
    "                    total_profit += self.trend[t] - bought_price\n",
    "                    starting_money += self.trend[t]\n",
    "\n",
    "                invest = ((starting_money - initial_money) / initial_money)\n",
    "                self.memory.append((state, action, invest, next_state, starting_money < initial_money))\n",
    "                state = next_state\n",
    "                if len(self.memory) > self.batch_size:\n",
    "                    self.replay(self.batch_size)\n",
    "            if (i + 1) % checkpoint == 0:\n",
    "                print('epoch: %d, total rewards: %f.3, total money: %f' % (i + 1, total_profit, starting_money))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:10:12.321499400Z",
     "start_time": "2023-10-17T15:10:12.300520900Z"
    }
   },
   "id": "250b69093832367b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_lkoh = pd.read_parquet('data/data_lkoh.parquet')\n",
    "\n",
    "head = 400\n",
    "split = 0.5\n",
    "initial_money = 10000\n",
    "window_size = 30\n",
    "skip = 4\n",
    "batch_size = 16\n",
    "df = data_lkoh.copy()\n",
    "data_100 = df.head(head)\n",
    "\n",
    "name = 'Q-learning agent'\n",
    "data_100 = data_100.sort_index(ascending=False)\n",
    "data_100 = data_100.reset_index(drop=True)\n",
    "# Assuming df is your DataFrame and 'Цена' is your target column\n",
    "data = data_100['Цена'].values.tolist()\n",
    "volume = data_100.Объём.values.tolist()\n",
    "day_of_week = data_100.dayofweek.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "\n",
    "dayofyear = data_100.dayofyear.values.tolist()  # assuming you have a column named 'dayofyear'\n",
    "EMA_20 = data_100.EMA_20.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "MACD = data_100.MACD.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "Signal_Line = data_100.Signal_Line.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "# Define the size of the training set. For example, 80% for training, 20% for testing.\n",
    "train_size = int(len(data) * split)\n",
    "\n",
    "# Split the data\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "# Train the agent with the training data\n",
    "close = data_100.Цена.values.tolist()[:train_size]\n",
    "\n",
    "agent = Agent(state_size = window_size * 7,  # updated state_size\n",
    "              window_size = window_size,\n",
    "              trend = train_data,\n",
    "              skip = skip,\n",
    "              batch_size = batch_size,\n",
    "              volume = volume[:train_size],\n",
    "              day_of_week = day_of_week[:train_size],\n",
    "              dayofyear = dayofyear[:train_size],\n",
    "              EMA_20 = EMA_20[:train_size],\n",
    "              MACD = MACD[:train_size],\n",
    "              Signal_Line = Signal_Line[:train_size],\n",
    "              )\n",
    "\n",
    "agent.train(iterations = 200, checkpoint = 5, initial_money = initial_money)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3adad1075413f816"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_default_parameters():\n",
    "    '''Получите параметры по умолчанию'''\n",
    "    params = {'units1': 8,\n",
    "              'units2': 8,\n",
    "              'units3': 8,\n",
    "              'optimizer': 'adam',\n",
    "              'batch_size': 128,\n",
    "              'learning_rate': 0.01,\n",
    "              'window_size': 30,\n",
    "              'skip': 2,\n",
    "              }\n",
    "    return params\n",
    "def zxc_main(PARAMS):\n",
    "    import pandas as pd\n",
    "    data_lkoh = pd.read_parquet('data/data_lkoh.parquet')\n",
    "\n",
    "    head = 400\n",
    "    split = 0.5\n",
    "    initial_money = 10000\n",
    "    window_size = PARAMS['window_size']\n",
    "    skip = PARAMS['skip']\n",
    "    batch_size =  PARAMS['batch_size']\n",
    "    df = data_lkoh.copy()\n",
    "    data_100 = df.head(head)\n",
    "\n",
    "    name = 'Q-learning agent'\n",
    "    data_100 = data_100.sort_index(ascending=False)\n",
    "    data_100 = data_100.reset_index(drop=True)\n",
    "    # Assuming df is your DataFrame and 'Цена' is your target column\n",
    "    data = data_100['Цена'].values.tolist()\n",
    "    volume = data_100.Объём.values.tolist()\n",
    "    day_of_week = data_100.dayofweek.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "\n",
    "    dayofyear = data_100.dayofyear.values.tolist()  # assuming you have a column named 'dayofyear'\n",
    "    EMA_20 = data_100.EMA_20.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "    MACD = data_100.MACD.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "    Signal_Line = data_100.Signal_Line.values.tolist()  # assuming you have a column named 'DayOfWeek'\n",
    "    # Define the size of the training set. For example, 80% for training, 20% for testing.\n",
    "    train_size = int(len(data) * split)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "    # Train the agent with the training data\n",
    "    close = data_100.Цена.values.tolist()[:train_size]\n",
    "\n",
    "    agent = Agent(state_size = window_size * 7,  # updated state_size\n",
    "                  window_size = window_size,\n",
    "                  trend = train_data,\n",
    "                  skip = skip,\n",
    "                  batch_size = batch_size,\n",
    "                  volume = volume[:train_size],\n",
    "                  day_of_week = day_of_week[:train_size],\n",
    "                  dayofyear = dayofyear[:train_size],\n",
    "                  EMA_20 = EMA_20[:train_size],\n",
    "                  MACD = MACD[:train_size],\n",
    "                  Signal_Line = Signal_Line[:train_size],\n",
    "                  )\n",
    "\n",
    "    agent.train(iterations = PARAMS['iterations'], checkpoint = 5, initial_money = initial_money)\n",
    "    # Update the trend, volume, day_of_week, dayofyear, EMA_20, MACD, and Signal_Line of the agent with the test data\n",
    "    agent.trend = test_data\n",
    "    agent.volume = volume[train_size:]\n",
    "    agent.day_of_week = day_of_week[train_size:]\n",
    "    agent.dayofyear = dayofyear[train_size:]\n",
    "    agent.EMA_20 = EMA_20[train_size:]\n",
    "    agent.MACD = MACD[train_size:]\n",
    "    agent.Signal_Line = Signal_Line[train_size:]\n",
    "\n",
    "\n",
    "    close = data_100.Цена.values.tolist()[train_size:]\n",
    "\n",
    "    states_buy_test, states_sell_test, total_gains_test, invest_test = agent.buy(initial_money = initial_money)\n",
    "    nni.report_final_result(total_gains_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        RECEIVED_PARAMS = nni.get_next_parameter()\n",
    "        LOG.debug(RECEIVED_PARAMS)\n",
    "        PARAMS = get_default_parameters()\n",
    "        PARAMS.update(RECEIVED_PARAMS)\n",
    "        LOG.debug(PARAMS)\n",
    "\n",
    "        Agent.build_model(PARAMS)\n",
    "        LOG.debug('Parameters received')\n",
    "        zxc_main(PARAMS)\n",
    "        LOG.debug('Model run')\n",
    "    except Exception as exception:\n",
    "        LOG.exception(exception)\n",
    "        LOG.debug('Error')\n",
    "        raise\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1fb43061c8a2c8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
